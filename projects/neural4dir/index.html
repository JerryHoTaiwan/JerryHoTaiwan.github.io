<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="description" content="Efficient 4D infrared spectroscopy via neural field reconstruction and adaptive sampling." />
  <meta name="keywords" content="Neural fields, 4D IR, 2DIR, spectroscopy, adaptive sampling, multidimensional spectroscopy" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Efficient 4D Infrared Spectroscopy via Neural Field Reconstruction and Adaptive Sampling</title>

  <!-- Analytics (keep/remove as you prefer) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- Fonts & CSS -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
  <link rel="stylesheet" href="./static/css/bulma.min.css" />
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./static/css/index.css" />
  <link rel="icon" href="./static/images/favicon.svg" />

  <!-- JS -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* Small helpers so it looks good out of the box */
    .section-title { margin-bottom: 0.5rem; }
    .section-subtitle { margin-top: 0; opacity: 0.8; }
    .metric-tag { margin-right: .4rem; }
    .img-caption { font-size: 0.9rem; opacity: 0.8; margin-top: .5rem; }
    .video-wrapper { position: relative; padding-top: 56.25%; border-radius: 12px; overflow: hidden; box-shadow: 0 8px 24px rgba(0,0,0,.08); }
    .video-wrapper video { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; }
    .carousel .item { text-align: center; }
    .card.elevated { box-shadow: 0 10px 28px rgba(0,0,0,.10); border-radius: 16px; }
    .is-narrow-text { max-width: 820px; margin: 0 auto; }
    .hero-teaser img { border-radius: 16px; box-shadow: 0 12px 36px rgba(0,0,0,.12); }
    .anchor-gap { scroll-margin-top: 80px; }
  </style>
</head>
<body>

<!-- ===== NAV ===== -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow:1; justify-content:center;">
      <a class="navbar-item" href="#top"><span class="icon"><i class="fas fa-home"></i></span></a>
      <a class="navbar-item" href="#overview">Overview</a>
      <a class="navbar-item" href="#results">Results</a>
      <a class="navbar-item" href="#gallery">4D Slices</a>
      <a class="navbar-item" href="#evolution">Adaptive Sampling</a>
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">More</a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://jerryhotaiwan.github.io">Home</a>
          <a class="navbar-item" href="https://jerryhotaiwan.github.io/projects/diff_wave_optics/">DiffWaveOptics</a>
          <!-- TODO: update once paper/code are public -->
          <a class="navbar-item" href="#">Paper (coming soon)</a>
          <a class="navbar-item" href="https://github.com/JerryHoTaiwan">Code (coming soon)</a>
        </div>
      </div>
    </div>
  </div>
</nav>

<a id="top" class="anchor-gap"></a>

<!-- ===== HERO ===== -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            Efficient 4D Infrared Spectroscopy via Neural Field Reconstruction and Adaptive Sampling
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://jerryhotaiwan.github.io">Chi-Jui Ho</a>, </span>
            <span class="author-block"><a href="https://www.linkedin.com/in/hhbhakta/?trk=public_profile_samename-profile">Harsh Bhakta</a>, </span>
            <span class="author-block"><a href="https://ultrafast.ucsd.edu">Xiong Wei</a>, </span>
            <span class="author-block"><a href="https://www.nickantipa.com">Nicholas Antipa</a></span>
          </div>
          <div class="is-size-5 publication-authors">
            <em>The page is under construction</em>
          </div>
          <div class="publication-links">
            <!-- TODO: update hrefs when arXiv / paper / code are ready -->
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark is-outlined">
                <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper (coming soon)</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark is-outlined">
                <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv (coming soon)</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/JerryHoTaiwan" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span><span>Code (coming soon)</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===== TEASER ===== -->
<div class="container is-max-desktop">
  <div class="hero-body">
    <div class="has-text-centered">
      <!-- TODO: replace with your 4D IR teaser figure -->
      <img src="./static/images/teaser_v8.pdf"
           alt="Neural4DIR teaser: sparse 4D sampling and dense neural reconstruction"
           style="width: 80%; height: auto;" />
    </div>
    <h2 class="subtitle has-text-centered">
      Neural fields and active sampling reconstruct densely sampled 4D spectra from sparse multidimensional IR measurements.
    </h2>
  </div>
</div>
</section>

<!-- ===== ABSTRACT ===== -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 section-title">Abstract</h2>
        <div class="content has-text-justified is-narrow-text">
          <p>
            Multidimensional infrared spectroscopy offers a window into ultrafast molecular dynamics through rich
            vibrational couplings and dynamical patterns. However, acquiring these high-dimensional spectra is
            time-consuming: when collecting 4D spectra—spatially and temporally resolved 2DIR—sampling densely across
            all dimensions quickly becomes prohibitively slow or infeasible in practice.
          </p>
          <p>
            To address this challenge, we introduce a neural representation framework to efficiently reconstruct dense
            4D spectra from sparse experimental measurements. We model the continuous spectral field with a
            coordinate-based multilayer perceptron that maps 4D coordinates to corresponding spectral intensities,
            enabling the recovery of densely sampled spectra from limited observations.
          </p>
          <p>
            Beyond passive reconstruction, we develop an active sampling strategy guided by reconstruction loss, which
            adaptively identifies the most informative sampling locations. Experimental results demonstrate that our
            method faithfully reconstructs oscillatory and dynamical spectral features using a fraction of the original
            data. By integrating neural fields with adaptive sampling, this work points toward practical multidimensional
            measurements in ultrafast spectroscopy.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===== (a) OVERVIEW / PIPELINE ===== -->
<a id="overview" class="anchor-gap"></a>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title">Neural field pipeline for 4D IR</h2>
    <p class="section-subtitle">
      Viewing spatially and temporally resolved 2DIR as a continuous 4D spectral field.
    </p>

    <div class="columns is-variable is-6">
      <!-- Text -->
      <div class="column">
        <div class="content">
          <h3 class="title is-5">From gridded spectra to continuous fields</h3>
          <ul>
            <li>
              <strong>Conventional acquisition:</strong>
              4D spectra sample spatial $(y,x)$ and spectroscopic $(t_2,\omega_1,\omega_3)$ dimensions on a dense grid,
              leading to long acquisition times and limited flexibility in experimental design.
            </li>
            <li>
              <strong>Our view:</strong>
              Treat the 4D spectrum as a continuous function
              \( S(y,x,t_2,\omega_1,\omega_3) \) and learn it directly from sparse measurements.
            </li>
          </ul>
          <p>
            <strong>Neural4DIR:</strong> A coordinate-based MLP maps normalized 4D coordinates to spectral intensities.
            The network is trained only on measured points, but can be queried at arbitrary resolutions along any
            combination of spatial, temporal, and frequency axes for visualization and analysis.
          </p>
        </div>
      </div>

      <!-- Figure -->
      <div class="column">
        <div class="card elevated">
          <div class="card-image pipeline-figure">
            <figure class="image">
              <!-- TODO: replace with your pipeline figure -->
              <img src="./static/images/pipeline_neural4dir.png"
                   alt="Neural4DIR pipeline: sparse sampling, neural field, dense reconstruction" />
            </figure>
          </div>
          <div class="card-content">
            <p class="img-caption">
              Sparse 4D samples from a spatially resolved 2DIR experiment are fed into a neural field that represents
              the continuous spectrum. The learned field is then evaluated on dense grids to obtain virtual fully
              sampled spectra and derived projections.
            </p>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>

<!-- ===== (b) RESULTS: SINGLE-FIGURE COMPARISON ===== -->
<a id="results" class="anchor-gap"></a>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title">Results: 4D reconstruction from sparse data</h2>
    <p class="section-subtitle">
      Neural4DIR preserves oscillatory peaks and dynamical features using a fraction of the original samples.
    </p>

    <div class="card elevated">
      <div class="card-image results-figure">
        <figure class="image">
          <!-- TODO: replace with your main reconstruction comparison -->
          <img src="./static/images/results_neural4dir_grid.png"
               alt="Grid comparison of 4D slices: ground truth vs. baselines vs. Neural4DIR" />
        </figure>
      </div>
      <div class="card-content">
        <p class="img-caption">
          <strong>Reconstruction quality on 4D spectra.</strong>
          Example 2D frequency–frequency slices at multiple waiting times and spatial positions. Neural4DIR closely
          matches the ground truth, preserving diagonal and cross peaks as well as their temporal beating, while
          baseline interpolation and compressed sensing methods smear or distort peak structure under the same
          sampling budget.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- ===== (c) "GALLERY": 4D SLICES & PROJECTIONS ===== -->
<a id="gallery" class="anchor-gap"></a>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title">4D slice gallery: spectra over time and space</h2>
    <p class="section-subtitle">
      Representative slices and projections used to evaluate reconstruction fidelity across dimensions.
    </p>

    <div class="table-container">
      <table class="table is-fullwidth is-bordered is-hoverable has-text-centered">
        <thead>
          <tr>
            <th>$(\omega_1,\omega_3)$ slice at fixed $(y,x,t_2)$</th>
            <th>$t_2$ trace at fixed $(y,x,\omega_1,\omega_3)$</th>
            <th>Spatial profile at fixed $(t_2,\omega_1,\omega_3)$</th>
            <th>Integrated intensity / summary metric</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>
              <figure class="image">
                <img src="./static/images/gallery_w1w3_slice.png"
                     alt="Frequency–frequency slice comparison" />
                <p class="img-caption">Frequency–frequency slice: ground truth vs. Neural4DIR.</p>
              </figure>
            </td>
            <td>
              <figure class="image">
                <img src="./static/images/gallery_t2_trace.png"
                     alt="Waiting-time trace comparison" />
                <p class="img-caption">$t_2$ beating curves recovered from sparse sampling.</p>
              </figure>
            </td>
            <td>
              <figure class="image">
                <img src="./static/images/gallery_spatial_profile.png"
                     alt="Spatial profile comparison" />
                <p class="img-caption">Spatial profile of peak amplitude across $y$ or $x$.</p>
              </figure>
            </td>
            <td>
              <figure class="image">
                <img src="./static/images/gallery_metrics.png"
                     alt="Metric summary plots" />
                <p class="img-caption">MSE and profile errors across sampling rates.</p>
              </figure>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>
</section>

<!-- Add this CSS in your <style> block -->
<style>
  .table td, .table th {
    vertical-align: middle; /* center vertically */
  }
</style>

<!-- ===== (d) EVOLVING SAMPLING PATTERNS / ACTIVE STRATEGY ===== -->
<a id="evolution" class="anchor-gap"></a>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title">Adaptive sampling over iterations</h2>
    <p class="section-subtitle">
      How the sampling pattern and reconstruction quality evolve under active learning.
    </p>

    <!-- Scoped styles just for this block -->
    <style>
      /* Equalize media height across image + videos */
      .evo-row { --media-h: 320px; }
      @media (max-width: 768px) { .evo-row { --media-h: 220px; } }
      @media (min-width: 1216px) { .evo-row { --media-h: 360px; } }

      .evo-row .cell {
        display:flex; flex-direction:column; align-items:center; justify-content:center; text-align:center;
      }

      .evo-row .thumb,
      .evo-row video {
        display:block;
        height: var(--media-h);
        width: auto;
        max-width: 100%;
        object-fit: contain;
        border-radius: 12px;
        box-shadow: 0 8px 24px rgba(0,0,0,.08);
      }

      .evo-row .caption { margin-top: .5rem; font-size: 0.9rem; opacity: .85; }

      /* Toolbar */
      .evo-controls { margin-top:.75rem; display:flex; gap:.5rem; align-items:center; justify-content:center; flex-wrap:wrap; }
    </style>

    <div class="columns is-variable is-6 evo-row">
      <!-- Left: initial sampling pattern (static) -->
      <div class="column cell">
        <h3 class="title is-6">Initial sampling pattern</h3>
        <img class="thumb" src="./static/images/sampling_initial.png" alt="Initial sampling pattern" />
        <div class="caption">Uniform or heuristic sampling before active refinement.</div>
      </div>

      <!-- Middle: sampling evolution (video or animated) -->
      <div class="column cell">
        <h3 class="title is-6">Sampling pattern evolution</h3>
        <video id="vid-lens" controls playsinline>
          <!-- TODO: replace with your sampling evolution video -->
          <source src="./static/videos/sampling_evolution.mp4" type="video/mp4" />
          <source src="./static/videos/sampling_evolution.webm" type="video/webm" />
        </video>
        <div class="caption">Active sampling concentrates measurements in informative regions.</div>
      </div>

      <!-- Right: reconstruction evolution (video or animated) -->
      <div class="column cell">
        <h3 class="title is-6">Reconstruction evolution</h3>
        <video id="vid-img" controls playsinline>
          <!-- TODO: replace with your reconstruction evolution video -->
          <source src="./static/videos/recon_evolution.mp4" type="video/mp4" />
          <source src="./static/videos/recon_evolution.webm" type="video/webm" />
        </video>
        <div class="caption">Recovered spectra sharpen and peaks stabilize as sampling progresses.</div>
      </div>
    </div>

    <!-- Optional: unified toolbar that controls both videos -->
    <div class="evo-controls">
      <button id="evo-play" class="button is-small is-info">Play</button>
      <button id="evo-pause" class="button is-small">Pause</button>
      <button id="evo-restart" class="button is-small">Restart</button>

      <label style="display:flex; align-items:center; gap:.35rem;">
        Speed
        <select id="evo-speed" class="select is-small">
          <option value="0.25">0.25×</option>
          <option value="0.5">0.5×</option>
          <option value="0.75">0.75×</option>
          <option value="1" selected>1×</option>
        </select>
      </label>

      <label class="checkbox" style="margin-left:.5rem;">
        <input id="evo-mute" type="checkbox" /> Muted
      </label>

      <label class="checkbox" style="margin-left:.5rem;">
        <input id="evo-sync" type="checkbox" checked /> Sync
      </label>
    </div>
  </div>
</section>

<!-- Tiny script for the unified toolbar -->
<script>
(function(){
  const v1 = document.getElementById('vid-lens');
  const v2 = document.getElementById('vid-img');
  if (!v1 || !v2) return;

  const btnPlay   = document.getElementById('evo-play');
  const btnPause  = document.getElementById('evo-pause');
  const btnRestart= document.getElementById('evo-restart');
  const selSpeed  = document.getElementById('evo-speed');
  const cbMute    = document.getElementById('evo-mute');
  const cbSync    = document.getElementById('evo-sync');

  function playAll(){ v1.play(); v2.play(); }
  function pauseAll(){ v1.pause(); v2.pause(); }
  function restartAll(){ v1.currentTime = 0; v2.currentTime = 0; playAll(); }

  function setRate(r){ v1.playbackRate = r; v2.playbackRate = r; }
  function setMute(m){ v1.muted = m; v2.muted = m; }

  if (btnPlay)    btnPlay.addEventListener('click', playAll);
  if (btnPause)   btnPause.addEventListener('click', pauseAll);
  if (btnRestart) btnRestart.addEventListener('click', restartAll);
  if (selSpeed)   selSpeed.addEventListener('change', e => setRate(parseFloat(e.target.value)));
  if (cbMute)     cbMute.addEventListener('change', e => setMute(e.target.checked));

  // Simple sync loop (keeps vids within ~50ms when playing)
  function syncTick(){
    if (cbSync && cbSync.checked && !v1.paused && !v2.paused) {
      const dt = v1.currentTime - v2.currentTime;
      if (Math.abs(dt) > 0.05) v2.currentTime = v1.currentTime;
    }
    requestAnimationFrame(syncTick);
  }
  requestAnimationFrame(syncTick);
})();
</script>

<!-- ===== BIBTEX ===== -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ho2025neural4dir,
  title   = {Efficient 4D Infrared Spectroscopy via Neural Field Reconstruction and Adaptive Sampling},
  author  = {Ho, Chi-Jui and Bhakta, Harsh and Wei, Xiong and Antipa, Nicholas},
  journal = {In preparation},
  year    = {2025}
}</code></pre>
  </div>
</section>

<!-- ===== FOOTER ===== -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/JerryHoTaiwan" class="external-link"><i class="fab fa-github"></i></a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
              Creative Commons Attribution-ShareAlike 4.0 International License
            </a>.
          </p>
          <p>
            You may borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website;
            please link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- ===== PAGE SCRIPTS ===== -->
<script>
  // Navbar burger for mobile
  document.addEventListener('DOMContentLoaded', () => {
    const burgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
    burgers.forEach(b => {
      b.addEventListener('click', () => {
        const target = document.querySelector('.navbar-menu');
        b.classList.toggle('is-active');
        target.classList.toggle('is-active');
      });
    });
  });

  // Init all carousels
  document.addEventListener('DOMContentLoaded', () => {
    if (window.bulmaCarousel) {
      bulmaCarousel.attach('.carousel', {
        slidesToScroll: 1,
        slidesToShow: 1,
        autoplay: true,
        loop: true,
        pauseOnHover: true
      });
    }
  });

  // Simple scrubber for iteration PNG sequence (kept from template; safe to leave unused)
  (function(){
    const rng = document.getElementById('evo-range');
    const img = document.getElementById('evo-img');
    if(!rng || !img) return;
    rng.addEventListener('input', () => {
      const k = String(rng.value).padStart(3,'0');
      img.src = `./static/evolution/frame_${k}.png`;
      img.alt = `Iteration ${rng.value}`;
    });
  })();
</script>

</body>
</html>